{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "For motivating examples in DVI\n",
    "We want to compare the difference between\n",
    "200-205 epochs with pure training data\n",
    "200-205 training data with wrong testing data,\n",
    "We will observe the boundaries and positions of data afterward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from cifar10_models.resnet import resnet18\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1331)\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "trainset = datasets.CIFAR10(root=\"data\", train=True, transform=train_transform, download=True)\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=200,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "device = torch.device(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "net = resnet18()\n",
    "path = \"E:\\\\DVI_exp_data\\\\resnet18_cifar10\\\\Model\\\\Epoch_{}\\\\subject_model.pth\".format(180)\n",
    "net.load_state_dict(torch.load(path))\n",
    "net.to(device)\n",
    "net.train()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01, nesterov=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch [1 / 20]: 100%|██████████| 250/250 [00:33<00:00,  7.46it/s, acc=0.945, loss=0.177] \n",
      " Epoch [2 / 20]: 100%|██████████| 250/250 [00:32<00:00,  7.76it/s, acc=0.955, loss=0.168] \n",
      " Epoch [3 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.87it/s, acc=0.965, loss=0.132] \n",
      " Epoch [4 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.87it/s, acc=0.975, loss=0.112] \n",
      " Epoch [5 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.86it/s, acc=0.96, loss=0.156]  \n",
      " Epoch [6 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.86it/s, acc=0.925, loss=0.241] \n",
      " Epoch [7 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.87it/s, acc=0.94, loss=0.192]  \n",
      " Epoch [8 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.87it/s, acc=0.975, loss=0.133] \n",
      " Epoch [9 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.86it/s, acc=0.96, loss=0.152]  \n",
      " Epoch [10 / 20]: 100%|██████████| 250/250 [00:32<00:00,  7.79it/s, acc=0.955, loss=0.156] \n",
      " Epoch [11 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.83it/s, acc=0.97, loss=0.116]  \n",
      " Epoch [12 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.96it/s, acc=0.965, loss=0.189] \n",
      " Epoch [13 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.96it/s, acc=0.965, loss=0.124] \n",
      " Epoch [14 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.95it/s, acc=0.98, loss=0.0881] \n",
      " Epoch [15 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.95it/s, acc=0.985, loss=0.0714]\n",
      " Epoch [16 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.96it/s, acc=0.97, loss=0.113]  \n",
      " Epoch [17 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.96it/s, acc=0.965, loss=0.119] \n",
      " Epoch [18 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.96it/s, acc=0.97, loss=0.118]  \n",
      " Epoch [19 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.95it/s, acc=0.97, loss=0.0873] \n",
      " Epoch [20 / 20]: 100%|██████████| 250/250 [00:31<00:00,  7.95it/s, acc=0.975, loss=0.115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    loop = tqdm(enumerate(trainloader), total=len(trainloader), leave=True)\n",
    "    for i, data in loop:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _,predictions = outputs.max(1)\n",
    "        num_correct = (predictions == labels).sum()\n",
    "        running_train_acc = float(num_correct) / float(inputs.shape[0])\n",
    "        # print statistics\n",
    "        loop.set_description(f\" Epoch [{epoch+1} / 20]\")\n",
    "        loop.set_postfix(loss=loss.item(), acc=running_train_acc)\n",
    "    torch.save(net.state_dict(), \"consecutive_epochs\\\\normal_{}.pth\".format(epoch+1))\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 images: 89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10('data', train=True, transform=test_transform, download=True)\n",
    "testset = datasets.CIFAR10('data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# net = resnet18()\n",
    "# net.load_state_dict(torch.load(path))\n",
    "# net.to(device)\n",
    "net.eval()\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=200,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d images: %d %%' % (total,\n",
    "        100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "retrain on test samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 images: 92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# record index on where model has a wrong prediction\n",
    "\n",
    "trainset = datasets.CIFAR10('data', train=True, transform=test_transform, download=True)\n",
    "testset = datasets.CIFAR10('data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "net = resnet18()\n",
    "net.load_state_dict(torch.load(path))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=200,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "correct = 0\n",
    "total = 0\n",
    "l=[]\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(testloader), total=len(testloader), leave=True):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        l.extend((predicted != labels).tolist())\n",
    "\n",
    "print('Accuracy of the network on the %d images: %d %%' % (total,\n",
    "                                                           100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "743"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tmp=np.arange(10000)\n",
    "mask = np.array(l)\n",
    "idxs = tmp[mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "class DataHandler(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.X[index], self.Y[index]\n",
    "        if self.transform is not None:\n",
    "            x = Image.fromarray(x)\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_tr = datasets.CIFAR10('data', train=True,  download=True)\n",
    "data_te = datasets.CIFAR10('data', train=False, download=True)\n",
    "X_tr = data_tr.data\n",
    "Y_tr = torch.from_numpy(np.array(data_tr.targets))\n",
    "X_te = data_te.data[idxs]\n",
    "Y_te = torch.from_numpy(np.array(data_te.targets))[idxs]\n",
    "\n",
    "X = np.concatenate((X_tr, X_te), axis=0)\n",
    "Y = torch.cat((Y_tr, Y_te), axis=0)\n",
    "datahandler = DataHandler(X, Y, train_transform)\n",
    "loader = DataLoader(\n",
    "    datahandler,\n",
    "    batch_size=200,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch [1 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.40it/s, acc=0.965, loss=0.15]  \n",
      " Epoch [2 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.37it/s, acc=0.944, loss=0.167] \n",
      " Epoch [3 / 20]: 100%|██████████| 254/254 [00:41<00:00,  6.19it/s, acc=0.937, loss=0.174] \n",
      " Epoch [4 / 20]: 100%|██████████| 254/254 [00:40<00:00,  6.32it/s, acc=0.958, loss=0.123] \n",
      " Epoch [5 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.41it/s, acc=0.93, loss=0.213]  \n",
      " Epoch [6 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.41it/s, acc=0.923, loss=0.22]  \n",
      " Epoch [7 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.44it/s, acc=0.944, loss=0.157] \n",
      " Epoch [8 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.48it/s, acc=0.958, loss=0.144] \n",
      " Epoch [9 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.951, loss=0.157] \n",
      " Epoch [10 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.44it/s, acc=0.958, loss=0.144] \n",
      " Epoch [11 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.44it/s, acc=0.972, loss=0.165] \n",
      " Epoch [12 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.48it/s, acc=0.944, loss=0.177] \n",
      " Epoch [13 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.972, loss=0.0952]\n",
      " Epoch [14 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.972, loss=0.11]  \n",
      " Epoch [15 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.972, loss=0.142] \n",
      " Epoch [16 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.965, loss=0.126] \n",
      " Epoch [17 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.979, loss=0.0863]\n",
      " Epoch [18 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.48it/s, acc=0.958, loss=0.126] \n",
      " Epoch [19 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.47it/s, acc=0.958, loss=0.136] \n",
      " Epoch [20 / 20]: 100%|██████████| 254/254 [00:39<00:00,  6.45it/s, acc=0.958, loss=0.161] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = resnet18()\n",
    "path = \"E:\\\\DVI_exp_data\\\\resnet18_cifar10\\\\Model\\\\Epoch_{}\\\\subject_model.pth\".format(180)\n",
    "net.load_state_dict(torch.load(path))\n",
    "net.to(device)\n",
    "net.train()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01, nesterov=True)\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    loop = tqdm(enumerate(loader), total=len(loader), leave=True)\n",
    "    for (i, data) in loop:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device=device,dtype=torch.long)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _,predictions = outputs.max(1)\n",
    "        num_correct = (predictions == labels).sum()\n",
    "        running_train_acc = float(num_correct) / float(inputs.shape[0])\n",
    "        # print statistics\n",
    "        loop.set_description(f\" Epoch [{epoch+1} / 20]\")\n",
    "        loop.set_postfix(loss=loss.item(), acc=running_train_acc)\n",
    "    torch.save(net.state_dict(), \"consecutive_epochs\\\\revised_{}.pth\".format(epoch+1))\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 images: 93 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# record index on where model has a wrong prediction\n",
    "\n",
    "trainset = datasets.CIFAR10('data', train=True, transform=test_transform, download=True)\n",
    "testset = datasets.CIFAR10('data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# net = resnet18()\n",
    "# net.load_state_dict(torch.load(path))\n",
    "# net.to(device)\n",
    "net.eval()\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=200,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "correct = 0\n",
    "total = 0\n",
    "l = []\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(testloader), total=len(testloader), leave=True):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        l.extend((predicted != labels).tolist())\n",
    "\n",
    "print('Accuracy of the network on the %d images: %d %%' % (total,\n",
    "                                                           100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "671"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"list_index.json\", \"w\") as f:\n",
    "    json.dump(l,f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "dr2",
   "language": "python",
   "display_name": "Python xianglinDR2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}